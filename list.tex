\begin{landscape}
\renewcommand*{\arraystretch}{1.9}

\newgeometry{top=10.3cm,bottom=2.5cm,left=2.5cm,right=1cm}
%\newgeometry{top=9.3cm,bottom=2cm,left=1.5cm,right=1cm}
{\scriptsize

\begin{longtable}{llllll}
\caption{Literature overview of the theoretical foundations of machine ethics (\gls{me})}
			\label{tab:lit_me} 
			\cr
			\toprule 
			\centering 
%1. header
\multicolumn{2}{c}{\centering\textbf{Motivation for ME}} & \multicolumn{2}{c}{\centering\textbf{Agency}} & \multicolumn{2}{c}{\centering\textbf{Theoretical Approaches}} \\ \toprule
%\endhead
%2. header
\multicolumn{1}{c}{\parbox{3cm}{\centering{Author}}} & \multicolumn{1}{c}{\parbox{5cm}{\centering{Main Statement}}} & \multicolumn{1}{c}{\parbox{3cm}{\centering{Author}}} & \multicolumn{1}{c}{\parbox{5cm}{\centering{Main Statement}}} & \multicolumn{1}{c}{\parbox{3cm}{\centering{Author}}} & \multicolumn{1}{c}{\parbox{5cm}{\centering{Main Statement}}} \\ \toprule\addlinespace[-0.5pt]%\endfirsthead 
 \specialrule{0.0em}{0.7em}{0.7em}
\endhead
%1
{\parbox{3cm}{\cite{prolegom_2000}}}  &    {\parbox{5cm}{ME will improve ethical alignment of humans; but risk of failure and corruptibility}}  
& {\parbox{3cm}{\cite{searle1980}}} &   {\parbox{5cm}{Chinese Room - machines lack capacity of understanding; but \textit{strong AI} may be developed in future}}   
&   {\parbox{3cm}{\cite{kant}}}  & {\parbox{5cm}{All moral principles can be reduced to one, the \textit{categorical imperative}}}   \\  \specialrule{0.0em}{0.7em}{0.7em}

%2
{\parbox{3cm}{\cite{asaro2006}}}  &     {\parbox{5cm}{With increasing autonomy of machines, an ethical dimension for machines becomes inevitable}}  & {\parbox{3cm}{\cite{bedau1996}}} &   {\parbox{5cm}{No sufficient accurate definition of vague concepts such as life, intelligence and agenthood because they admit to continuous change}}    &   {\parbox{3cm}{\cite{bentham1799}}}  & {\parbox{5cm}{Utilitarism: calculating overall net pleasure by performing moral arithmetic}}     \\    \specialrule{0.0em}{0.7em}{0.7em}

%3
{\parbox{3cm}{\cite{why_me2006}}}  & {\parbox{5cm}{We are already dealing with autonomous machines violating ethical standards. Therefore, the development of ME is vital to guide machines when acting in the human world}}  & {\parbox{3cm}{\cite{franklin1996}}} &   {\parbox{5cm}{No Agreement among scientists about definition of agenthood even in principle}}  &   {\parbox{3cm}{\cite{ross1930}}}  & {\parbox{5cm}{Action-based approach \textit{multiple prima facie duties} where weaker duties get overwritten when conflicting with stronger duties}}     \\  \specialrule{0.0em}{0.7em}{0.7em}

%4
{\parbox{3cm}{\cite{robot_good2010}}}  &     {\parbox{5cm}{Ethical reasoning in humans is often biased, sloppy and self-interest is the main driving factor behind decisions. Therefore, ME will improve the alignment with ethical standards even in humans}}   & {\parbox{3cm}{\cite{prolegom_2000}}} &   {\parbox{5cm}{Emotions are source of moral and immoral behavior. Therefore, we should create emotionless ethical machines}} &   {\parbox{3cm}{\cite{rawls1951}}}  & {\parbox{5cm}{\textit{Reflective Equilibrium}: weight all duties involved and choose the one with highest weight}}  \\  \specialrule{0.0em}{0.7em}{0.7em}

%5
{\parbox{3cm}{\cite{metaethics2011}}}  &     {\parbox{5cm}{There should be no autonomous system without an ethical dimension which acts within ethical ramifications in an acceptable manner}}   & {\parbox{3cm}{\cite{ai_can2000}}} &   {\parbox{5cm}{There should not be autonomous ethical machines; only expert systems should be developed}}     &   {\parbox{3cm}{\cite{mill1974}}}  & {\parbox{5cm}{Utilitarism: conditions are consistency, completeness and practicability}}    \\  \specialrule{0.0em}{0.7em}{0.7em}
%6

{\parbox{3cm}{\cite{yablonsky}}}  &     {\parbox{5cm}{Danger of \textit{robo-paths} ME will increase irresponsibility among humans and makes humans less ethical}}   & {\parbox{3cm}{\cite{aa2004}}} &   {\parbox{5cm}{Non-conscious beings can be ethical agents because ethical principles are subject to rational deliberation}} &   {\parbox{3cm}{\cite{gips}}}  & {\parbox{5cm}{Distinguishes two approaches to ME: consequentialist and deontological theories}}  \\  \specialrule{0.0em}{0.7em}{0.7em}
%7
{\parbox{3cm}{\cite{kirkpatrick2015}}}  &     {\parbox{5cm}{ME is necessary when dealing with ethical dilemmas where even ethicists disagree on, ME can advance and sharpen the ethical discussion}}   & {\parbox{3cm}{\cite{why_me2006}}} &   {\parbox{5cm}{Researchers involved in implementing ME advocate a stoic view where emotions are not necessary and, yet, even dangerous for ethical decision-making}}  &   {\parbox{3cm}{\cite{prolegom_2000}}}  & {\parbox{5cm}{There is no single acceptable ethical theory}}  \\  \specialrule{0.0em}{0.7em}{0.7em}
%8
{\parbox{3cm}{\cite{harford2016}}}  &     {\parbox{5cm}{\textit{Automation Paradox}: ME will make decision-making easier but at the same time there is a \textit{skill erosion} and humans loose their decision-making abilities}}  & {\parbox{3cm}{\cite{irrgang2006ethical}}} &   {\parbox{5cm}{Moral agent does not need free will but needs to be somewhat characterized as subject or person}} &   {\parbox{3cm}{\cite{me2004}}}  & {\parbox{5cm}{Only rules which are complete, consistent and practicable can be considered}} \\  \specialrule{0.0em}{0.7em}{0.7em}
%9
{\parbox{3cm}{\cite{vanderelst2016}}}  &     {\parbox{5cm}{Risk of moral reasoning systems being easily corruptible by malicious designer, hacker or coding errors}}  & {\parbox{3cm}{\cite{nadeau2006only}}} &   {\parbox{5cm}{Only ethical decisions based on strict logical basis are free. Therefore, humans cannot be ethical agents but machines can}} &   {\parbox{3cm}{\cite{asaro2006}}} & {\parbox{5cm}{Cultural differences in ethical principles must be included when developing ethical machines}}    \\  \specialrule{0.0em}{0.7em}{0.7em} 
%10
{\parbox{3cm}{\cite{baum2017}}} &     {\parbox{5cm}{When ME is applied, we must strengthen the necessity of accountable and verifiable machines}}   & {\parbox{3cm}{\cite{sullins2006}}} &   {\parbox{5cm}{Intention can be ascribed by machines because behavior can be explained by its beliefs and goals}}   &   {\parbox{3cm}{\cite{dennett2006}}}  & {\parbox{5cm}{"AI makes Philosophy honest"}}   \\  \specialrule{0.0em}{0.7em}{0.7em}
%11
{\parbox{3cm}{\cite{charisi2017}}}  &     {\parbox{5cm}{Due to the lack of software security and hacking attacks, ethical machines can easily be turned into unethical actuators}}  & {\parbox{3cm}{\cite{dreyfus2007}}} &   {\parbox{5cm}{Facts and history play a major role but there is the potential to develop \textit{strong AI}}} &   {\parbox{3cm}{\cite{I_robot2006}}}  & {\parbox{5cm}{Criticism on Utilitarianism because machines might cause harm for greater good}}   \\  \specialrule{0.0em}{0.7em}{0.7em}
%12
{\parbox{3cm}{\cite{standards2017}}}  &     {\parbox{5cm}{Machines can outperform humans even in the ethical domain which can lead to social instabilities}}    & {\parbox{3cm}{\cite{bringsjord2008ethical}}} &   {\parbox{5cm}{Machines cannot become ethical agents because they are not programmed to become it}}   & {\parbox{3cm}{\cite{metaethics2011}}}    & {\parbox{5cm}{Ethical theories must not be complete and consistent and should be applied in limited domains}}  \\  \specialrule{0.0em}{0.7em}{0.7em}

%13
{\parbox{3cm}{\cite{wachter2017}}}  &     {\parbox{5cm}{Importance of transparent ethical decision-making in machines}}     &  {\parbox{3cm}{\cite{ai_agency2009}}} &   {\parbox{5cm}{Only conscious beings can be ethical agents}} 
& {\parbox{3cm}{\cite{brundage2014}}}   & {\parbox{5cm}{Challenges of value pluralism and value imperialism}}    \\  \specialrule{0.0em}{0.7em}{0.7em}


{\parbox{3cm}{\cite{weller2017}}} &   {\parbox{5cm}{Ethical machines must be verifiable and accountable}} & {\parbox{3cm}{\cite{kurzweil2013}}} &   {\parbox{5cm}{\textit{Strong AI} will be possible in future; we have the ability to model the mind but not emotions (yet)}} 
&   {\parbox{3cm}{\cite{cointe2016}}} & {\parbox{5cm}{Learning judgments in multi-agent environments based on rationalist and explicit approaches}} \\  \specialrule{0.0em}{0.7em}{0.7em}


{\parbox{3cm}{\cite{mot_risks2018}}}  &     {\parbox{5cm}{There are many benefits but also risks; when applying ME, verification and transparency is the key for acceptable ME}}    
& {\parbox{3cm}{\cite{dennett2014hal}}} &   {\parbox{5cm}{Machines are not ethical agents now, but they might be in the future when we set an appropriate \textit{Level of Abstraction}}}   
&   {\parbox{3cm}{\cite{mot_risks2018}}}  & {\parbox{5cm}{Only moral dilemmas and trade-offs require moral reasoning; we do not need ethical principles for every decision}}     \\  \specialrule{0.0em}{0.7em}{0.7em}

{\parbox{3cm}{\cite{yu2018}}}  &     {\parbox{5cm}{Sometimes decisions have to be made even though there is no correct solution to it; there is no acceptable solution for such situations, yet}}   
& {\parbox{3cm}{\cite{ai}}} &   {\parbox{5cm}{Machines can perceived as agents because they have the capacity to act}}  
& {\parbox{3cm}{\cite{yu2018}}} & {\parbox{5cm}{Main focus on combination of rule-based and example-based approaches with limited success even in specific domains}}       \\  \specialrule{0.0em}{0.7em}{0.7em}
\bottomrule
\end{longtable}
%\end{spacing}
}
\restoregeometry
\end{landscape}


\clearpage

